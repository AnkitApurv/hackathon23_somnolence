{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9b88817f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import concatenate\n",
    "import itertools\n",
    "import re\n",
    "from math import sqrt\n",
    "import os\n",
    "import warnings\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "import matplotlib\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.stattools import adfuller,grangercausalitytests\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM,Dropout, RNN\n",
    "from keras_tuner import BayesianOptimization, RandomSearch, GridSearch\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99e65e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=False):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg\n",
    "\n",
    "def adf_test(df):\n",
    "    result = adfuller(df.values)\n",
    "    print('ADF Statistics: %f' % result[0])\n",
    "    print('p-value: %f' % result[1])\n",
    "    print('Critical values:')\n",
    "    for key, value in result[4].items():\n",
    "        print('\\t%s: %.3f' % (key, value))\n",
    "    return result[1]\n",
    "\n",
    "def check_stationarity(dataset):\n",
    "    stationary_fields=[]\n",
    "    non_stationary_fields=[]\n",
    "    for col in dataset.columns:\n",
    "        print('______%s_______'%col)\n",
    "        p_value=adf_test(dataset[col])\n",
    "        if p_value<=0.05:\n",
    "            stationary_fields.append(col)\n",
    "        else:\n",
    "            non_stationary_fields.append(col)\n",
    "\n",
    "    print('Number of stationary fields :%s'%len(stationary_fields))\n",
    "    print('Number of non stationary fields :%s'%len(non_stationary_fields))\n",
    "    \n",
    "    return stationary_fields,non_stationary_fields\n",
    "\n",
    "def feature_selection(reframed_dataset,number_of_lags,target_index, keep_granger_causality,keep_all_lags):\n",
    "    col_pattern=r't-%s'%(number_of_lags)\n",
    "    target_features=['var%s(t-%s)'%(target_index,i) for i in range(1,number_of_lags)]\n",
    "    target=['var%s(t)'%(target_index)]\n",
    "    \n",
    "    if keep_all_lags==False:\n",
    "        tlag_col=[col for col in reframed_dataset.columns if re.search(col_pattern,col,re.I)!=None]\n",
    "        reframed_dataset_final=reframed_dataset[tlag_col+target_features+target]\n",
    "    else:\n",
    "        tlag_col=[col for col in reframed_dataset.columns if re.search(r'\\(t\\)',col,re.I)==None]\n",
    "        reframed_dataset_final=reframed_dataset[tlag_col+target]\n",
    "    \n",
    "    if keep_granger_causality==True:\n",
    "        reframed_dataset_final_transformed = reframed_dataset_final.dropna()\n",
    "        i=1\n",
    "        stationary_fields,non_stationary_fields=check_stationarity(reframed_dataset_final_transformed)\n",
    "        \n",
    "        while(len(non_stationary_fields)>0):\n",
    "            print('Taking %sth difference'%(i))\n",
    "            reframed_dataset_final_transformed = reframed_dataset_final_transformed.diff().dropna()\n",
    "            stationary_fields,non_stationary_fields=check_stationarity(reframed_dataset_final_transformed)\n",
    "            i=i+1\n",
    "            \n",
    "\n",
    "        correlated_col=[]\n",
    "        for col in [col for col in reframed_dataset_final_transformed.columns if col!='var%s(t)'%(target_index)]:\n",
    "            granger_ = grangercausalitytests(reframed_dataset_final_transformed[['var%s(t)'%(target_index), col]], 4)\n",
    "            if (granger_[1][0]['ssr_chi2test'][1]<=0.05)|(granger_[2][0]['ssr_chi2test'][1]<=0.05)|(granger_[3][0]['ssr_chi2test'][1]<=0.05)|(granger_[4][0]['ssr_chi2test'][1]<=0.05):\n",
    "                correlated_col.append(col)\n",
    "    else:\n",
    "        correlated_col=[col for col in reframed_dataset_final.columns if col!='var%s(t)'%(target_index)]\n",
    "    \n",
    "    reframed_dataset_final_features=reframed_dataset_final[correlated_col+target].copy()\n",
    "    reframed_dataset_final_features.dropna(inplace=True)\n",
    "    return reframed_dataset_final_features\n",
    "\n",
    "\n",
    "def scale_and_split(reframed_dataset_final_features):\n",
    "    scaler=MinMaxScaler()\n",
    "    reframed_dataset_final_scaled=scaler.fit_transform(reframed_dataset_final_features)\n",
    "    reframed_dataset_final_scaled=pd.DataFrame(reframed_dataset_final_scaled,columns=reframed_dataset_final_features.columns)\n",
    "\n",
    "    reframed_dataset_final_scaled.index=reframed_dataset_final_features.index\n",
    "    \n",
    "    reframed_dataset_final_scaled_values=reframed_dataset_final_scaled.values\n",
    "    train_limit=reframed_dataset_final_scaled_values.shape[0]-12\n",
    "\n",
    "    train_X=reframed_dataset_final_scaled_values[0:train_limit,:-1]\n",
    "    train_Y=reframed_dataset_final_scaled_values[0:train_limit,-1]\n",
    "\n",
    "    test_X=reframed_dataset_final_scaled_values[train_limit:,:-1]\n",
    "    test_Y=reframed_dataset_final_scaled_values[train_limit:,-1]\n",
    "    \n",
    "    # reshape input to be 3D [samples, timesteps, features]\n",
    "    train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "    test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "    print(train_X.shape, train_Y.shape, test_X.shape, test_Y.shape)\n",
    "    \n",
    "    return train_X, train_Y, test_X, test_Y,scaler\n",
    "\n",
    "def hyperparameter_tuning(train_X, train_Y, test_X, test_Y, country):\n",
    "    \n",
    "    def build_model(hp):\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(LSTM(hp.Int('input_unit',min_value=10,max_value=500,step=1),return_sequences=True, \n",
    "                       input_shape=(train_X.shape[1],train_X.shape[2])))\n",
    "        for i in range(hp.Int('n_layers', 1, 4)):\n",
    "            model.add(LSTM(hp.Int(f'lstm_{i}_units',min_value=10,max_value=500,step=1),return_sequences=True))\n",
    "        model.add(LSTM(hp.Int('layer_2_neurons',min_value=10,max_value=500,step=1)))\n",
    "\n",
    "        model.add(Dropout(hp.Float('Dropout_rate',min_value=0,max_value=0.99,step=0.1)))\n",
    "\n",
    "        model.add(Dense(1, activation=hp.Choice('dense_activation',values=['sigmoid','relu','tanh','linear','selu','elu'],\n",
    "                                                default='relu')))\n",
    "\n",
    "        model.compile(loss='mean_squared_error', \n",
    "                      optimizer=keras.optimizers.Adam(hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])),metrics =['mse'])\n",
    "        return model\n",
    "    \n",
    "    tuner= GridSearch(\n",
    "        build_model,\n",
    "        objective='mse',\n",
    "        max_trials=10,\n",
    "        executions_per_trial=1,\n",
    "        overwrite=True,\n",
    "        project_name='keras_tuning_%s_LSTM'%(country)\n",
    "        )\n",
    "\n",
    "    tuner.search(\n",
    "            x=train_X,\n",
    "            y=train_Y,\n",
    "            epochs=100,\n",
    "            batch_size=72,\n",
    "            validation_data=(test_X,test_Y),\n",
    "    )\n",
    "    \n",
    "    best_model = tuner.get_best_models(num_models=1)[0]\n",
    "    \n",
    "    return best_model\n",
    "\n",
    "def rmse_calculator(best_model,test_X, test_Y,scaler):\n",
    "    \n",
    "    # make a prediction\n",
    "    yhat = best_model.predict(test_X)\n",
    "\n",
    "    # invert scaling for forecast\n",
    "    test_X_reshaped = test_X.reshape((test_X.shape[0], test_X.shape[2]))\n",
    "    inv_yhat = concatenate((test_X_reshaped, yhat), axis=1)\n",
    "    inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "    inv_yhat = inv_yhat[:,-1]\n",
    "\n",
    "    # invert scaling for actual\n",
    "    test_Y_reshaped = test_Y.reshape((len(test_Y), 1))\n",
    "    inv_y = concatenate((test_X_reshaped,test_Y_reshaped), axis=1)\n",
    "    inv_y = scaler.inverse_transform(inv_y)\n",
    "    inv_y = inv_y[:,-1]\n",
    "    \n",
    "    rmse = sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "    print('Original Values: %s'%inv_y)\n",
    "    print('Predicted Values: %s'%inv_yhat)\n",
    "    \n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c719c7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(mrd_directory, number_of_lags, target_index, country, keep_granger_causality, keep_all_lags):\n",
    "    df_MRD=pd.read_excel(mrd_directory)\n",
    "    df_MRD['Time']=pd.to_datetime(df_MRD['Time'],format='%Y-%m')\n",
    "    df_MRD=df_MRD.set_index('Time')\n",
    "\n",
    "    reframed_dataset = series_to_supervised(df_MRD, number_of_lags, 1)\n",
    "    \n",
    "    reframed_dataset_final_features=feature_selection(reframed_dataset,number_of_lags,target_index,keep_granger_causality,keep_all_lags)\n",
    "    \n",
    "    train_X, train_Y, test_X, test_Y,scaler=scale_and_split(reframed_dataset_final_features)\n",
    "    \n",
    "    best_model=hyperparameter_tuning(train_X, train_Y, test_X, test_Y, country)\n",
    "    \n",
    "    rmse=rmse_calculator(best_model,test_X, test_Y,scaler)\n",
    "    \n",
    "    return best_model,scaler,rmse,str(reframed_dataset.shape),str(reframed_dataset_final_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c2826b",
   "metadata": {},
   "source": [
    "# EXPERIMENT-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fee66a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 00m 30s]\n",
      "mse: 0.0013423407217487693\n",
      "\n",
      "Best mse So Far: 0.0008916739607229829\n",
      "Total elapsed time: 00h 06m 42s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "Original Values: [5.3 5.2 4.9 4.9 5.3 5.2 5.2 5.1 5.  5.  5.  5. ]\n",
      "Predicted Values: [5.49403079 5.46846077 5.48195317 5.3382588  5.37924559 5.84874704\n",
      " 5.77051603 5.80913804 5.68498523 5.61344274 5.63813771 5.66663379]\n",
      "0.5471985008357692\n"
     ]
    }
   ],
   "source": [
    "canada_model, canada_scaler, canada_test_rmse, canada_pre_shape, canada_post_shape=main(r'Datasets\\Canada_LSTM_MRD.xlsx',5,1,'Canada',True,False)\n",
    "\n",
    "print(canada_test_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2384d060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 00m 35s]\n",
      "mse: 0.0006314384518191218\n",
      "\n",
      "Best mse So Far: 0.0006314384518191218\n",
      "Total elapsed time: 00h 05m 30s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "Original Values: [7.4 7.5 7.5 7.5 7.3 7.2 7.1 7.2 7.2 7.2 7.1 7. ]\n",
      "Predicted Values: [7.33389376 7.40188015 7.4877393  7.54327795 7.55448675 7.55587878\n",
      " 7.51877462 7.4807671  7.56534937 7.59535189 7.63327245 7.57986614]\n",
      "0.33813753900368465\n"
     ]
    }
   ],
   "source": [
    "france_model, france_scaler, france_test_rmse, france_pre_shape, france_post_shape=main(r'Datasets\\France_LSTM_MRD.xlsx',5,1,'France',True,False)\n",
    "\n",
    "print(france_test_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db02ee55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 00m 34s]\n",
      "mse: 0.00024674442829564214\n",
      "\n",
      "Best mse So Far: 0.0002304707159055397\n",
      "Total elapsed time: 00h 06m 57s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "Original Values: [3.  3.  3.  3.  3.1 3.1 3.1 3.1 3.  3.  2.9 2.9]\n",
      "Predicted Values: [3.00688552 2.9441796  2.9        2.9        2.9        2.9\n",
      " 2.9        2.9        2.9        2.9        2.9        2.9       ]\n",
      "0.13011639886904694\n"
     ]
    }
   ],
   "source": [
    "germany_model, germany_scaler, germany_test_rmse, germany_pre_shape, germany_post_shape=main(r'Datasets\\Germany_LSTM_MRD.xlsx',5,1,'Germany',True,False)\n",
    "\n",
    "print(germany_test_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "faa1e3e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 00m 29s]\n",
      "mse: 0.001212011557072401\n",
      "\n",
      "Best mse So Far: 0.001164554967544973\n",
      "Total elapsed time: 00h 06m 21s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "Original Values: [8.3 8.2 8.1 8.  8.  8.1 8.  7.9 7.9 7.9 8.  8. ]\n",
      "Predicted Values: [8.44104999 8.29410549 8.24400452 8.21089192 8.06123775 8.00884373\n",
      " 8.05245563 7.99464988 7.95993867 7.91107864 7.90162231 7.8941192 ]\n",
      "0.10891038360968584\n"
     ]
    }
   ],
   "source": [
    "italy_model, italy_scaler, italy_test_rmse, italy_pre_shape, italy_post_shape=main(r'Datasets\\Italy_LSTM_MRD.xlsx',5,1,'Italy',True,False)\n",
    "\n",
    "print(italy_test_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e76cac81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 00m 27s]\n",
      "mse: 0.0005045221769250929\n",
      "\n",
      "Best mse So Far: 0.0005045221769250929\n",
      "Total elapsed time: 00h 06m 38s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001D7B0A8A820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "Original Values: [3.8 3.7 3.8 3.8 3.8 3.6 3.5 3.6 3.7 3.7 3.7 3.7]\n",
      "Predicted Values: [4.02222247 3.93212927 3.88217597 3.88866465 3.90214238 3.81525025\n",
      " 3.70331729 3.61036413 3.62926253 3.67095043 3.72269431 3.77864207]\n",
      "0.13803365471676862\n"
     ]
    }
   ],
   "source": [
    "uk_model, uk_scaler, uk_test_rmse, uk_pre_shape, uk_post_shape=main(r'Datasets\\UK_LSTM_MRD.xlsx',5,1,'UK',True,False)\n",
    "\n",
    "print(uk_test_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2352fc07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 00m 35s]\n",
      "mse: 0.0035264750476926565\n",
      "\n",
      "Best mse So Far: 0.003472226671874523\n",
      "Total elapsed time: 00h 06m 09s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001D7B0A8AF70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "Original Values: [3.6 3.6 3.6 3.5 3.7 3.5 3.7 3.6 3.5 3.4 3.6 3.5]\n",
      "Predicted Values: [4.33160041 4.62155    4.39613931 4.08394837 3.62891416 3.78196191\n",
      " 3.59702017 3.73032752 3.66425997 3.5456735  3.45406563 4.06448804]\n",
      "0.5044740326766116\n"
     ]
    }
   ],
   "source": [
    "us_model, us_scaler, us_test_rmse, us_pre_shape, us_post_shape=main(r'Datasets\\US_LSTM_MRD.xlsx',5,1,'US',True,False)\n",
    "\n",
    "print(us_test_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4fef3dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 00m 38s]\n",
      "mse: 0.0012412657961249352\n",
      "\n",
      "Best mse So Far: 0.0012412657961249352\n",
      "Total elapsed time: 00h 07m 29s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "Original Values: [2.6 2.6 2.6 2.6 2.6 2.5 2.6 2.6 2.5 2.5 2.4 2.6]\n",
      "Predicted Values: [2.64932756 2.59365514 2.56721132 2.55342952 2.54355308 2.54355308\n",
      " 2.48283333 2.50122999 2.52231394 2.45943856 2.44363935 2.39521947]\n",
      "0.08178561493853004\n"
     ]
    }
   ],
   "source": [
    "japan_model, japan_scaler, japan_test_rmse, japan_pre_shape, japan_post_shape=main(r'Datasets\\Japan_LSTM_MRD.xlsx',5,5,'Japan',True,False)\n",
    "\n",
    "print(japan_test_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae3b582",
   "metadata": {},
   "source": [
    "# SAVING MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a6c27eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'Models/US_LSTM_Model.sav','wb') as f:\n",
    "    pickle.dump(us_model,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cf9f7113",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'Models/UK_LSTM_Model.sav','wb') as f:\n",
    "    pickle.dump(uk_model,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d0b1ea74",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'Models/Italy_LSTM_Model.sav','wb') as f:\n",
    "    pickle.dump(italy_model,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "937b864a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'Models/Germany_LSTM_Model.sav','wb') as f:\n",
    "    pickle.dump(germany_model,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f0e8719b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'Models/France_LSTM_Model.sav','wb') as f:\n",
    "    pickle.dump(france_model,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ea1b4083",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'Models/Canada_LSTM_Model.sav','wb') as f:\n",
    "    pickle.dump(canada_model,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b0659562",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'Models/Japan_LSTM_Model.sav','wb') as f:\n",
    "    pickle.dump(japan_model,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f660cd0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
